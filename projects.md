---
layout: page
title: Projects
permalink: /projects/
---

*Disclaimer:* I will try to keep this list updated, but please check my github for my latest projects. 


## Projects:

* <a href="https://github.com/ja3067/char-rnn-tensorflow">**Char-RNN:**</a> My latest project is a general-purpose character-level Long Short-Term Memory (LSTM) RNN for learning from and interpreting text, which can be trained on any large text dataset with good performance and excellent results.

* <a href="">**Generative Adversarial Networks (GANs):**</a> These networks, trained on MNIST, CIFAR-10, and several face datasets, are capable of learning to produce unique image data from existing datasets. They work by pitting two neural networks against each other: one, a classifier, tries to tell which image is real and which is fake, while the other tries to generate more realistic images.

* <a href="">**Deep Convolution Classifiers:**</a> These are simple, classical convolution networks trained on MNIST, CIFAR-10, and the ILSVRC datasets, which can classify even complex images with high accuracy into anywhere between 2 and 10000 classes.

* <a href="https://github.com/ja3067/gradient-descent-examples">**Logistic/Linear Regression in Numpy:**</a> These scripts use backpropogation to perform linear and logistic regression, with an algorithm implemented from scratch in Numpy/Python.

Other side-projects include various <a href="https://github.com/ja3067/examples/blob/master/preprocessing.py">sanitization utilities</a> for images and text, and some curiosities like a <a href="https://github.com/ja3067/examples/blob/master/mandelbrot.py">Mandelbrot generator</a> and some scientific visualization datasets.

## Tensorflow/Keras Tutorials

* <a href="https://github.com/ja3067/tensorflow-keras-tutorials/blob/master/CNN%20Tutorial%20MNIST.ipynb">**MNIST CNN Classifier Tutorial:**</a> This notebook is a simple tutorial introduction to image classification in Keras, using the MNIST dataset. We cover fully connected networks, various CNNs, and hidden layer visualization to help understand how the model learns.

* <a href="https://github.com/ja3067/tensorflow-keras-tutorials/blob/master/SGD%20Linear%20Regression%20in%20Numpy%20Tutorial.ipynb">**Introduction to SGD, Vectorization, and Linear Regression in Numpy:**</a> In this tutorial, we implement the "backpropogation" algorithm for simple linear regression on MNIST, first by looping over the weights, and then using a vectorized implementation in Numpy. We talk about the calculus of Stochastic Gradient Descent, and prepare for a logistic regression implementation in the next tutorial. For anyone interesting in actually doing Machine Learning by hand, without a framework, or in understanding what Tensorflow is actually doing, this should be helpful.

