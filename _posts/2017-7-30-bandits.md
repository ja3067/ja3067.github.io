---
layout: post
title: "K-Armed Bandits: Understanding Reinforcement Learning"
use_math: true
excerpt: <div class="excerpt"><img src="/images/placeholder.png"><br></div>
thumbnail: "https://ja3067.github.io/images/placeholder.png"
---

The k-armed bandits problem. If you've read anything about reinforcement learning, the term has probably come up, but even after a lot of technical reading, it still evokes the image of a group of seven-armed men waylaying travelers in a deserted street. The actual problem is rather more pedestrian, but not less interesting. The k-armed bandits problem is a classic problem is statistics and reinforcement learning that asks the following:

<div class="quote">A man is playing a number of slot machines at the same time, each of which has a fixed distribution of possible rewards. For simplicity, we assume the distributions are normal with fixed, but different, means and deviations. The man can pull a total of 1000 levers, and he starts off knowing nothing about the distributions. What strategy should he employ to earn the most money in those 1000 episodes?</div>

We can start by brainstorming some possible strategies. One strategy is to pull a bunch of levers at random until we have a pretty good idea which is the best one on average, and then pull that one repeatedly. Another is to always pull the best one, except for a small percentage of the time when you pull another randomly chosen lever. A third, more elaborate possibility is to keep track of how much we really know about each distribution, and pull them less often at random if we're more certain about its reward distribution. These all seem like reasonable strategies, but they all have downsides.
