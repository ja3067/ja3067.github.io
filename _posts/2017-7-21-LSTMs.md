---
layout: post
title: Char-RNN in Tensorflow: Lessons Learned
---

The past week has seen me diving headfirst into the world of Recurrent Neural Networks (or RNNs), networks capable of sequential learning. Humans are amazing at learning because we learn in context; we can remember and contextualize a word in a sentence that last appeared pages ago. Our neural networks should be able to do the same thing. 

RNN inputs are sequences - like sentences, which are sequences of characters or words, or even images, which are sequences of pixels. 
