<!DOCTYPE html>
<html>
  <head>
    <title>K-Armed Bandits: Understanding Reinforcement Learning – Jacob Austin – Machine learning, made simple.</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="" />
    <meta property="og:description" content="" />
    

    
    <meta property="og:image" content="https://jacobaustin123.github.io/images/placeholder.png" />
    

    <meta name="author" content="Jacob Austin" />
    <meta name="keywords" content="Jacob Austin, jaustin, ja3067, Jacob, Austin, Columbia, Columbia University, physics, math, CS, machine learning, Tensorflow, tf, keras, music, piano, Waynflete, github, computer science, LSTM, RNN, CNN, tutorial, plasma physics, plasma, computer vision, NLP, blog">
    
    <meta property="og:title" content="K-Armed Bandits: Understanding Reinforcement Learning" />
    <meta property="twitter:title" content="K-Armed Bandits: Understanding Reinforcement Learning" />
    


    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Jacob Austin - Machine learning, made simple." href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://avatars0.githubusercontent.com/u/28993550" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Jacob Austin</a></h1>
            <p class="site-description">Machine learning, made simple.</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
            <a href="https://github.com/jacobaustin123">Github</a>
            <a href="/projects">Projects</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true
    }
  });
</script>



<article class="post">
  <h1 class="post-header">K-Armed Bandits: Understanding Reinforcement Learning</h1>
  <div class="date">
    July 30, 2017
  </div>

  <div class="entry">
    <p>The k-armed bandits problem. If you’ve read anything about reinforcement learning, the term has probably come up, but even after a lot of technical reading, it still evokes the image of a group of seven-armed men waylaying travelers in a deserted street. The actual problem is rather more pedestrian, but not less interesting. The k-armed bandits problem is a classic problem is statistics and reinforcement learning that asks the following:</p>

<div class="quote">A man is playing a number of slot machines at the same time, each of which has a fixed distribution of possible rewards. For simplicity, we assume the distributions are normal with fixed, but different, means and deviations. The man can pull a total of 1000 levers, and he starts off knowing nothing about the distributions. What strategy should he employ to earn the most money in those 1000 episodes?</div>

<p>We can start by brainstorming some possible strategies. One strategy is to pull a bunch of levers at random until we have a pretty good idea which is the best one on average, and then pull that one repeatedly. Another is to always pull the best one, except for a small percentage of the time when you pull another randomly chosen lever. A third, more elaborate possibility is to keep track of how much we really know about each distribution, and pull them less often at random if we’re more certain about its reward distribution. These all seem like reasonable strategies, but they all have downsides.</p>

  </div>

  
</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:ja3067@columbia.edu"><i class="svg-icon email"></i></a>


<a href="https://github.com/jacobaustin123"><i class="svg-icon github"></i></a>

<a href="https://www.linkedin.com/in/jacob-austin-b52191133/"><i class="svg-icon linkedin"></i></a>



<a href="http://stackoverflow.com/users/5187645/jaustin"><i class="svg-icon stackoverflow"></i></a>


        </footer>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-103049335-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/bandits/',
		  'title': 'K-Armed Bandits: Understanding Reinforcement Learning'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
