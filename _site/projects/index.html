<!DOCTYPE html>
<html>
  <head>
    <title>Projects – Jacob Austin – Machine learning, made simple.</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Machine learning, made simple.">
    <meta property="og:description" content="Machine learning, made simple." />
    

    

    <meta name="author" content="Jacob Austin" />
    <meta name="keywords" content="Jacob Austin, jaustin, ja3067, Jacob, Austin, Columbia, Columbia University, physics, math, CS, machine learning, Tensorflow, tf, keras, music, piano, Waynflete, github, computer science, LSTM, RNN, CNN, tutorial, plasma physics, plasma, computer vision, NLP, blog">
    
    <meta property="og:title" content="Projects" />
    <meta property="twitter:title" content="Projects" />
    


    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Jacob Austin - Machine learning, made simple." href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://avatars0.githubusercontent.com/u/28993550" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Jacob Austin</a></h1>
            <p class="site-description">Machine learning, made simple.</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
            <a href="https://github.com/ja3067">Github</a>
            <a href="/projects">Projects</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="page">

  <h1>Projects</h1>

  <div class="entry">
    <p><em>Disclaimer:</em> I will try to keep this list updated, but please check my github for my latest projects.</p>

<h2 id="networks">Networks:</h2>

<ul>
  <li>
    <p><a href="https://github.com/ja3067/char-rnn-tensorflow"><strong>Char-RNN:</strong></a> My latest project is a general-purpose character-level Long Short-Term Memory (LSTM) RNN for learning from and interpreting text, which can be trained on any large text dataset with good performance and excellent results.</p>
  </li>
  <li>
    <p><a href="https://github.com/ja3067/tic-tac-toe-minimax"><strong>Tic Tac Toe:</strong></a> In this repository, I implement a number of reinforcement learning and minimax algorithms for playing tic-tac-toe, including Q-learning, alpha-beta pruning, heuristic evaluation functions, and the classical minimax algorithm.</p>
  </li>
  <li>
    <p><a href="https://github.com/ja3067/gradient-descent-examples"><strong>Reinforcement Learning:</strong></a> These scripts demonstrate solutions to some classic reinforcement learning problems, and solve optimal control problems for OpenAI challenges. The k-armed-bandit script compares and visualizes algorithms for solving the classic problem in reinforcement learning.</p>
  </li>
  <li>
    <p><a href=""><strong>Generative Adversarial Networks (GANs):</strong></a> These networks, trained on MNIST, CIFAR-10, and several face datasets, are capable of learning to produce unique image data from existing datasets. They work by pitting two neural networks against each other: one, a classifier, tries to tell which image is real and which is fake, while the other tries to generate more realistic images.</p>
  </li>
  <li>
    <p><a href=""><strong>Deep Convolution Classifiers:</strong></a> These are simple, classical convolution networks trained on MNIST, CIFAR-10, and the ILSVRC datasets, which can classify even complex images with high accuracy into anywhere between 2 and 10000 classes.</p>
  </li>
  <li>
    <p><a href="https://github.com/ja3067/gradient-descent-examples"><strong>Logistic/Linear Regression in Numpy:</strong></a> These scripts use backpropogation to perform linear and logistic regression, with an algorithm implemented from scratch in Numpy/Python.</p>
  </li>
</ul>

<p>Other side-projects include <a href="https://github.com/ja3067/demos/blob/master/python-notes.ipynb">general python notes</a> and <a href="https://github.com/ja3067/demos/blob/master/python-notes-modules.ipynb">module tutorials</a>, and various scientific visualization tools. More small scripts and utilities will be added gradually.</p>

<h2 id="tensorflowkeras-tutorials">Tensorflow/Keras Tutorials</h2>

<ul>
  <li>
    <p><a href="https://github.com/ja3067/tensorflow-keras-tutorials/blob/master/CNN%20Tutorial%20MNIST.ipynb"><strong>MNIST CNN Classifier Tutorial:</strong></a> This notebook is a simple tutorial introduction to image classification in Keras, using the MNIST dataset. We cover fully connected networks, various CNNs, and hidden layer visualization to help understand how the model learns.</p>
  </li>
  <li>
    <p><a href="https://github.com/ja3067/tensorflow-keras-tutorials/blob/master/SGD%20Linear%20Regression%20in%20Numpy%20Tutorial.ipynb"><strong>Introduction to SGD, Vectorization, and Linear Regression in Numpy:</strong></a> In this tutorial, we implement the “backpropogation” algorithm for a simple linear regression model on MNIST, first using an iterative approach (looping over the weights), and then trying a vectorized implementation in Numpy. We talk about the calculus of Stochastic Gradient Descent, and prepare for a logistic regression implementation in the next tutorial.</p>
  </li>
</ul>

<h2 id="other-work">Other Work:</h2>

<ul>
  <li>
    <p><a href="https://github.com/ja3067/examples/blob/master/preprocessing.py"><strong>Image Preprocessing Script:</strong></a> A script which preprocesses image data and saves it in convenient formats, with a large number of options including resizing, greyscale conversion, and channel normalization.</p>
  </li>
  <li>
    <p><a href="https://github.com/ja3067/demos/blob/master/mandelbrot.py"><strong>Mandelbrot Generator:</strong></a> A small Mandelbrot generator, with arbitrary resolution and size.</p>
  </li>
  <li>
    <p><a href="https://github.com/ja3067/demos/blob/master/central_limit.py"><strong>Central Limit Theorem Demonstration:</strong></a> A small script which demonstrates the converge of the mean of samples from arbitrary distributions to a normal distribution.</p>
  </li>
</ul>

  </div>
</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:ja3067@columbia.edu"><i class="svg-icon email"></i></a>


<a href="https://github.com/ja3067"><i class="svg-icon github"></i></a>

<a href="https://www.linkedin.com/in/jacob-austin-b52191133/"><i class="svg-icon linkedin"></i></a>



<a href="http://stackoverflow.com/users/5187645/jaustin"><i class="svg-icon stackoverflow"></i></a>


        </footer>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-103049335-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/projects/',
		  'title': 'Projects'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
